{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training an unsupervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project must include some elements of unsupervised learning, but you are welcome to include some supervised or other learning approaches as well.\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Jensen McKenzie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents and how they are measured\n",
    "- what you will be doing with the data\n",
    "- how performance/success will be measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "The financial markets are complex ecosystems influenced by a myriad of factors, including economic indicators, geopolitical events, investor sentiment, and company-specific information. Analyzing and understanding the intricate relationships within this dynamic environment is crucial for making informed investment decisions. Traditional approaches to stock analysis often fall short in capturing the nuanced patterns and interactions that drive market movements.\n",
    "\n",
    "In recent years, machine learning and data science techniques have gained prominence in financial analysis, offering a more sophisticated and data-driven perspective. One such powerful technique is stock clustering, a method that groups similar stocks based on historical price movements, trading volumes, and other relevant features. The underlying assumption is that stocks with similar characteristics are likely to respond similarly to market dynamics.\n",
    "\n",
    "There has been a lot of relevant work conducted regarding this topic, with interesting results. In a study done in Argentinia about using clusetring technquies to enhance stock returns forecasting, they used K-means and for each cluster, used ARIMA(Autoregressive Integrated Moving Average) and LSTM(Long Short-Term Memory) forecasting models and test their performances. The study showed that there was enhanced forecasting precision by leveraging the additional information offered by clustering methods, underscoring the significance of relevant data selection in preprocessing. Moreover, using the whole sample of stocks only worsened the forecasting ability of LSTM model<a name=\"fn1\"></a>[<sup>[1]</sup>](#fn1note).\n",
    "\n",
    "In another paper, the researchers used clustering-enhanced deep learning framework to predict the stock prices using LSTM, RNN (Recurrent Neural Network), and GRU(Gated Recurrent Unit) models. To enhance clustering effectiveness in the context of stock price time series, this study introduces a novel similarity measure known as Logistic Weighted Dynamic Time Warping (LWDTW) for calculating distances between stock price data points. In comparison with benchmark measures, such as Euclidean distance and standard Dynamic Time Warping (DTW), LWDTW incorporates a weight function that acknowledges the non-normal distribution of stock returns. Empirical analysis of individual US stock price data reveals characteristics like dynamic, non-stationary, nonlinear, and chaotic behaviors, better represented by a logistic distribution probability density function with higher peaks and fatter tails. LWDTW leverages this insight by using the logistic distribution as the weight function, assigning appropriate weights to extreme return observations while emphasizing normal return observations in distance matrix calculations. This approach ensures that the clustering method accounts for the unique patterns in stock returns<a name=\"fn2\"></a>[<sup>[2]</sup>](#fn2note).\n",
    "\n",
    "Although a lot of researches focus on predicitng the stock prices like above, they all gave very helpful insights on how to effectively utilize clustering methods for much accurate prediciting and forecasting aftwerwards. Both studies mentioned above displayed the importance of proper clustering methods, giving us tips and even prompted to create a new clustering methods. Overall, understandings of these studies could gave us better idea of clustering and make us more aware of things to consider when implementing clustering on stocks and utilize their knowledge into our own project. \n",
    "\n",
    "<sup id=\"fn1\">1. [Javier Vásquez Sáenz, Facundo Manuel Quiroga, Aurelio F. Bariviera,Data vs. information: Using clustering techniques to enhance stock returns forecasting, International Review of Financial Analysis, Volume 88, 2023, 102657, ISSN 1057-5219, https://doi.org/10.1016/j.irfa.2023.102657.]<a href=\"#ref1\" title=\"Jump back to footnote 1 in the text.\">↩</a></sup>\n",
    "\n",
    "<sup id=\"fn2\">2. [Li, M., Zhu, Y., Shen, Y. et al. Clustering-enhanced stock price prediction using deep learning. World Wide Web 26, 207–232 (2023). https://doi.org/10.1007/s11280-021-01003-0]<a href=\"#ref2\" title=\"Jump back to footnote 2 in the text.\">↩</a></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "This project will use financial data provided by the python packages [yfinance](https://pypi.org/project/yfinance/) and [morningstar-data](https://pypi.org/project/morningstar-data/). Both of these datasets contain data for almost every ticker symbol availible on the stock market. This includes current price, past price, various performance metrics, and other financial data.\n",
    "\n",
    "We plan to primarily use yfinance for the majority of the training data, and use morningstar-data to validate our model, using helpful proprietary metrics curated by financial experts. An observation for a single stock ticker would consist of one row of data, with each column representing a different financial metric. The critical variables would be the price of the stock, the volume of the stock, and the various performance metrics.\n",
    "\n",
    "One possible issue with this data is lack of normalization. For instance, we could have a stock trading at \\$1000, and another trading at \\$10. This would make it difficult to compare the two stocks, as the price of the stock would be heavily weighted in the model. We would need to normalize the data to ensure that the model is not biased towards stocks with higher prices. Additionally, we would most likely want to consider market cap as a metric, because this is a key indicator of risk and volatility, and can be used to normalize the data. We may need to transform any information about a stock's market sector using one-hot encoding, as this could be a key indicator of the stock's performance, and a possible evaluation metric. Because of this, we will look into metrics that place each ticker in a relatively short list of categories, such as the GICS sector classification, which is a widely used classification system for stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Why might your solution work? Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination. Get creative!\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
